1100-qt(0.975,df=8)*10
choose(3,4)*0.5+choose(4,4)*0.5
choose(3,4)*0.5*0.25+choose(4,4)*0.5
choose(3,4)*0.5*0.25+choose(4,4)*0.5*0.25
choose(3,4)+choose(4,4)
choose(3,4)
choose(4,3)
choose(4,3)*0.5*0.25+choose(4,4)*0.5*0.25
1-choose(4,3)*0.5*0.25+choose(4,4)*0.5*0.25
1-(choose(4,3)*0.5*0.25+choose(4,4)*0.5*0.25)
swirl()
library(swirl)
swirl()
install.package(swirl)
install.packages(swirl)
install.packages('swirl')
install_from_swirl("Statistical Inference")
install_from_swirl("Statistical Inference")
install_from_swirl("Statistical_Inference")
install_from_swirl("StatisticalInference")
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
33/36
deck
52
4/52
13/52
0
12/52
3/51
2/51
0.4*1.6
(0.4*1.6)/(1*1)
mypdf
mypdf(0,1.6)
mypdf(0)
integerate(mypdf,0,1.6)
integrate(mypdf,0,1.6)
1
sqrt(2)
99.7*0.5
99.7*0.001
0.997*0.001
(1-0.997)*0.999
(1-0.985)*0.999
(0.997*0.001)/(0.997*0.001+(1-0.997)*0.999)
(0.997*0.001)/(0.997*0.001+(1-0.985)*0.999)
?pnorm
pnorm(0,mean=0.01,sd=0.04,lower.tail=FALSE)
pnorm(0,mean=0.01,sd=0.04,lower.tail=FALSE)*qnorm(0.95)
qnorm(0,mean=0.01,sd=0.04,lower.tail=FALSE)
pnorm(0,mean=0.01,sd=0.04,lower.tail=FALSE)
pnorm(0,mean=0.01,sd=0.004,lower.tail=FALSE)
pnorm(0,mean=0.01,sd=0.4,lower.tail=FALSE)
pnorm(0,mean=0.01,sd=0.04,lower.tail=FALSE)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(testing)
qplot(mixtures$CompressiveStrength)
qplot(mixtures$CompressiveStrength,colour=Age)
qplot(mixtures$CompressiveStrength,colour="Age")
qplot(mixtures$CompressiveStrength,colour="FlyAsh")
featureplot(x=mixtures[,c("Cement","BlastFurnaceSlag","FlyAsh","Water","Superplasticizer", "CoarseAggregate","FineAggregate","Age")],y=mixture$CompressiveStrength,plot="Pairs")
featurePlot(x=mixtures[,c("Cement","BlastFurnaceSlag","FlyAsh","Water","Superplasticizer", "CoarseAggregate","FineAggregate","Age")],y=mixture$CompressiveStrength,plot="Pairs")
featurePlot(x=mixtures[,c("Cement","BlastFurnaceSlag","FlyAsh","Water","Superplasticizer", "CoarseAggregate","FineAggregate","Age")],y=mixtures$CompressiveStrength,plot="Pairs")
featurePlot(x=mixtures[,c("Cement","BlastFurnaceSlag","FlyAsh","Water","Superplasticizer","FineAggregate","Age")],y=mixtures$CompressiveStrength,plot="Pairs")
training[,"Superplasticizer"]
min(training[,"Superplasticizer"])
hist(training[,"Superplasticizer"])
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
is.begin("IL")
begin("IL")
start("IL")
names(training).start("IL")
start(names(training),"IL")
?start
names(training)[1][1]
names(training)[1][2]
names(training)[[1]][2]
names(training)[[1]]
names(training)[[1]][1,1]
names(training)[[1]][1]
names(training)[[1]][2]
?start.with
begin.with
?begin
?start
qnorm(0.95,mean=1100,sd=75)
qnorm(0.95,mean=1100,sd=7.5)
choose(5,4)
choose(5,4)*(0.5)^5
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
model<-train(adData$diagnosis~.,data=training,method="glm")
model<-train(diagnosis~.,data=training,method="glm")
install.packages("e1071")
model<-train(diagnosis~.,data=training,method="glm")
model
?confutionMatrix
confusionMatrix(testing,predict(model,testing))
confusionMatrix(predict(model,testing))
confusionMatrix(testing,predict(model,testing))
confusionMatrix(testing$diagnosis,predict(model,testing))
model<-train(diagnosis~.,data=training,method="glm",preProcess="pca")
confusionMatrix(testing$diagnosis,predict(model,testing))
model<-train(diagnosis~.,data=training,method="glm")
confusionMatrix(testing$diagnosis,predict(model,testing))
>preProcess
?preProcess
model<-train(diagnosis~.,data=training,method="glm",preProcess="pca",thresh=0.8)
model<-train(diagnosis~.,data=training,method="glm",preProcess="pca",thresh=0.8)
preproc<-preProcess(diagnosis,method="pca",thresh=0.8,data=Training)
preproc<-preProcess(diagnosis,method="pca",thresh=0.8,data=Training)
preproc<-preProcess(training,method="pca",thresh=0.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
set.seed(125)
train<-createDataPartition(segmentationOriginal$case,p=0.7)
segmentationOriginal$case
train<-createDataPartition(segmentationOriginal$Case,p=0.7)
training<-segmentationOriginal[,train]
train<-createDataPartition(segmentationOriginal$Case,p=0.7,list=FALSE)
training<-segmentationOriginal[,train]
train
segmentationOriginal[,train]
training<-segmentationOriginal[segmentationOriginal,]
training<-segmentationOriginal[train,]
testing<-segmentationOriginal[-train,]
model<-train(Case~.,data=training)
model<-train(Case~.,data=training)
model<-train(Case~.,data=training)
model<-train(Case~.,data=training,method="rf")
swirl()
library(swirl)
swirl()
install_from_swirl("R Programming")
swirl()
library(swirl)
swirl()
TRUE==TRUE
(FALSE==TRUE)==FALSE
6==7
6<7
10<=10
5!=7
!(5==7)
FALSE & FALSE
c(TRUE,FALSE,FALSE)
TRUE&c(TRUE,FALSE,FALSE)
TRUE&&c(TRUE,FALSE,FALSE)
TRUE|c(TRUE,FALSE,FALSE)
TRUE||c(TRUE,FALSE,FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6>4)
identical('twins', 'twins')
xor(5==6,!FALSE)
ints <- sample(10)
ints
ints>5
which(ints>7)
any(ints<0)
all(ints>0)
?na.omit
?vif
data(car)
library(car)
?car
data(dar)
data(car)
?vif
x<-c(1,2,3)
y<c(4,5,6)
y<-c(4,5,6)
model<-lm(y~x)
vif(model)
?influence.measures
exit
end
library(swirl)
swirl()
33/36
deck
13*4
4/52
4*((1/(52*51*50*49*48))
)
12/52
3/51
2/50
2/51
x<-c(1,2,3,4)
Y<-C(3,4,5,6)
Y<-C(3,4,5,6)
Y<-c(3,4,5,6)
plot(x,y.main="Test")
plot(x,y,main="Test")
plot(x,Y,main="Test")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
min(training$SuperPlasticizer)
training$SuperPlasticizer
training[,'SuperPlasticizer']
training[,"SuperPlasticizer"]
training
names(training)
training$Superplasticizer
min(training$Superplasticizer)
max(training$Superplasticizer)
log(0)
exit
logout
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
names(trianSA)
names(trainSA)
model<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA)
library(caret)
set.seed(13234)
model<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
result<-predict(model,trainSA)
missClass(trainSA[,"chd"],result)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
model2<-train(y~.,data=vowel.train,method="rpart")
varImp(model2)
model2<-train(y~.,data=vowel.train,method="rf")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model<-train(CompressiveStrength~.,method="svm")
model<-train(CompressiveStrength~.,method="svm",data=training)
library(e1071)
model<-train(CompressiveStrength~.,method="svm",data=training)
?svm
model<-svm(CompressiveStrength~.,data=training)
result<-predict(model,testing)
sqrt(sum((result-testing[,"CompressiveStrength"])^2))
source('C:/Users/Public/Documents/RSME.R')
RSME(result,testing[,"CompressiveStrength"])
source('C:/Users/Public/Documents/RSME.R')
source('C:/Users/Public/Documents/RSME.R')
source('C:/Users/Public/Documents/RSME.R')
RMSE(result,testing[,"CompressiveStrength"])
source('C:/Users/Public/Documents/RSME.R')
source('C:/Users/Public/Documents/Error.R')
RMSE(result,testing[,"CompressiveStrength"])
vdc<-c(12,10,8,6,4)
vled<-c(3.94,3.88,3.80,3.74,3.60)
I<-c(6.9,5.5,4.3,3.2,2.4)
plot(vdc,vled,main="VDC - VLED",xlab="VDC(V)",ylab="VLED(V)")
plot(vdc,vled,main="VDC - VLED",xlab="VDC(V)",ylab="VLED(V)",type='l')
plot(vdc,I,main="VDC - VLED",xlab="VDC(V)",ylab="VLED(V)",type='l')
plot(vdc,I,main="VDC - I",xlab="VDC(V)",ylab="I(mA)",type='l')
plot(vled,I,main="VLED - I",xlab="VLED(V)",ylab="I(mA)",type='l')
clear all
clear all
library(caret)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
library(forcast)
library(forecast)
install.packages("forecast")
library(forecast)
?bats
model<-bats(tstrain)
tstest<-ts(testing$visitsTumblr)
forecast(tstest)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
?lasso
model1<-train(CompressiveStrength~.,data=training,method="lasso")
model1<-train(CompressiveStrength~.,data=training,method="lasso")
model1
?plot.enet
plot.enet(model1)
?enet
?bats
?lasso
plot.enet(model1)
model1
coefficients(model1)
model1.coef
coef(model1)
model1
result<-predict(model1,testing)
plot.enet(result)
?plot.enet
library(lubridate)  # For year() function below
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model1<-(tstrain)
tstest<-ts(testing$visitsTumblr)
forecast(tstest)
?forecast
forecast(model1)
objec<-forecast(model1)
predict(obj,tstest)
predict(objec,tstest)
tstest
?plot.enet
?lasso
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
model<-lassO(CompressiveStrength~.,data=training)
model<-lasso(CompressiveStrength~.,data=training)
model<-train(CompressiveStrength~.,data=training,method="lasso")
plot.enet(model)
model
names(model)
names(conceret)
names(concrete)
result<-predict(model,testing)
result
varImp(model)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model1<-train(diagnosis~.,data=training,method="rf")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
model1<-train(diagnosis~.,data=training,method='rf')
model2<-train(diagnosis~.,data=training,method='bgm')
library(bgm)
model2<-train(diagnosis~.,data=training,method='gbm')
model3<-train(diagnosis~.,data=training,method='lda')
pre1<-predict(model1,testing)
pre2<-predict(model2,testing)
pre3<-predict(model3,testing)
temp<-data.frame(pre1,pre2,pre3,testing$diagnosis)
model3<-train(diagnosis~.,data=temp,method='rf')
model3<-train(testing.diagnosis~.,data=temp,method='rf')
result<-predict(model3,testing)
confusionMatrix(result,testing[,'diagnosis'])
model3<-train(diagnosis~.,data=training,method='lda')
pre1<-predict(model1,testing)
pre2<-predict(model2,testing)
pre3<-predict(model3,testing)
temp<-data.frame(pre1,pre2,pre3,training$diagnosis)
pre1<-predict(model1,training)
pre2<-predict(model2,training)
pre3<-predict(model3,training)
temp<-data.frame(pre1,pre2,pre3,training$diagnosis)
model4<-train(training.diagnosis~.,data=temp,method='rf')
result<-predict(model4,testing)
result<-predict(model4,testing)
pre1<-predict(model1,testing)
pre2<-predict(model2,testing)
pre3<-predict(model3,testing)
temp<-data.frame(pre1,pre2,pre3,testing$diagnosis)
model4<-train(testing.diagnosis~.,data=temp,method='rf')
result<-predict(model4,temp)
confusionMatrix(result,temp$diagnosis)
confusionMatrix(result,temp[,'diagnosis'])
diagnosis
temp
confusionMatrix(result,temp[,'temp.diagnosis'])
confusionMatrix(result,temp[,'testing.diagnosis'])
result<-predict(model2,testing)
confusionMatrix(result,testing[,'diagnosis'])
father.son
library(UsingR)
father.son
?father.son
shiny::runApp('C:/Users/m/Desktop/Developing Data Product/Project')
x=c(1,2,3,1)
y=c(1,2,3,4)
xp=c(x,x[1])
yp=c(y,y[1])
lines(xp,yp)
xp
xp
xp
yp
plot(x,y)
lines(x,y)
lines(xp,yp)
x
y
x[0]
x[1]
x[2]
x[]
2x[4]
x[4]
x[5]
x[4]
x[0]
class(x)
x[1]
x[2]
x[3]
x[4]
x[5]
x[4]
?aggregate
library(usingR)
library(UsingR)
temp<-father.son
aggregate(temp)
aggregate(temp,mean)
aggregate(temp,FUN=mean)
aggregate(temp,"sheight",FUN=mean)
aggregate(temp,c("sheight"),FUN=mean)
?transorm
?transform
shiny::runApp('C:/Users/m/Desktop/shiny')
